	\documentclass[12pt]{article}
	\pagenumbering{gobble}
	\usepackage{amsmath}
	\usepackage{graphicx}
	\graphicspath{ {c:/users/nicho_000/desktop/miniproject/} }
	\addtolength{\oddsidemargin}{-.775in}
	\addtolength{\evensidemargin}{-.5in}
	\addtolength{\textwidth}{1.75in}
	\addtolength{\topmargin}{-.875in}
	\addtolength{\textheight}{1.75in}
	
	\usepackage[procnames]{listings}
	\usepackage{color}
	
	\definecolor{keywords}{RGB}{255,0,90}
	\definecolor{comments}{RGB}{0,0,113}	
	\definecolor{red}{RGB}{160,0,0}
	\definecolor{green}{RGB}{0,150,0}
		
	\lstset{language=Python, 
		basicstyle=\ttfamily\small, 
		keywordstyle=\color{keywords},
		commentstyle=\color{green},
		stringstyle=\color{red},
		showstringspaces=false,
		procnamekeys={def,class}}
	
	\begin{document}
	
	
	\begin{titlepage}
        \centering
		{\scshape\LARGE University of Waterloo \par}
		\vspace{1cm}
		{\scshape\Large AMATH 251\par}
		\vspace{1.5cm}
		{\huge\bfseries Numerical Approximations for Differential Equations \par}
		\vspace{2cm}
		{\Large\itshape Nick Mitchell\\David Yeghshatyan\par}
		\vfill
		\par
		\textsc{K.G. Lamb}
		\vfill
		{\large October 8, 2015 \par}
	\end{titlepage}
	
	\section{Quadratic Approximation}

	\hspace{5mm} Numerical approximation of the equation $y^{\prime}=xy$, $y(0)=1$ , with three different approximation methods.
	
	\begin{center}
		\begin{tabular}{ |c||c|c|c| } 
			\hline
			\multicolumn{4}{|c|}{\textbf{Numerical Approximations}} \\
			\hline
			\hline
			Steps & Quadratic & RK2 & Euler \\
			\hline
			1 & 1.5 & 1.5 & 1.0\\ 
			\hline
			2 & 1.58203 & 1.59961 & 1.25\\ 
			\hline
			4 & 1.62617 & 1.63422 & 1.41943\\ 
			\hline
			8 & 1.64219 & 1.64477 & 1.52401\\ 
			\hline
			\hline
			$e^{\frac{1}{2}}$ & 1.64872 & 1.64872 & 1.64872\\ 
			\hline
		\end{tabular}
	\end{center}
	
	We see here that the Quadratic approximation is far superior to Euler's method, yet RK2 is still a slightly better approximation.
	
	\section{Showing that RK2 is a second order method}
	
	$
	\begin{aligned}
	&RK2:  
	&y_{j+1} 
	&= y_{j} + f(x_{j}+\frac{h}{2} , y^{*}){h} ,\hspace{3mm} where\hspace{3mm} y^{*} = y_{j} + f(x_{j},y_{j}){\frac{h}{2}}  
	\\	
	\\
	&Consider:
	&f(x_{j}+\frac{h}{2} , y^{*})
	&=f(x_{j}+\frac{h}{2} , y_{j} + f(x_{j},y_{j}){\frac{h}{2}}) 
	\hspace{3mm} where\hspace{3mm} y\prime(x)=f(x,y)
	\\
	&Gives 
	&&=f(x_{j}+\frac{h}{2} , y_{j} + y^{\prime}{\frac{h}{2}}) 
	\\ 
	&&&=f(x_{j}+\frac{h}{2} , y_{j}(x_{j}) + y^{\prime}(x_{j}){\frac{h}{2}}) 
	\\
	\\ 
	&Recall \hspace{2mm} Taylor's \hspace{2mm} Theorem: 
	&T(x)
	&=\sum\limits_{n=0}^\infty \frac{T^{(n)}(x_{0})}{n!}(x-x_{0})^{n}
	\\ 
	&let\hspace{3mm} x=x_{j}+\frac{h}{2} ; x_{0}=x_{j}; 
	&T(x_{j}+\frac{h}{2})
	&=\sum\limits_{n=0}^\infty \frac{T^{(n)}(x_{j})}{n!}(x_{j}+\frac{h}{2}-x_{0})^{n}
	\\
	&&&=\sum\limits_{n=0}^\infty \frac{T^{(n)}(x_{j})}{n!}(\frac{h}{2})^{n}
	\\
	&&&=\frac{T^{(0)}(x_{j})}{0!}(\frac{h}{2})^{0} + \frac{T^{(1)}(x_{j})}{1!}(\frac{h}{2})^{1} + \bigcirc(h^{2})
	\\
	&&&=T(x_{j}) + T^{\prime}(x_{j})(\frac{h}{2}) + \bigcirc(h^{2})
	\\
	\\
	&So 
	&y_{j} + y^{\prime}{\frac{h}{2}} 
	&= y(x_{j}+\frac{h}{2})+ \bigcirc(h^{2})
	\\
	&And 
	&f(x_{j}+\frac{h}{2} , y^{*})
	&=f(x_{j}+\frac{h}{2} , y_{j} + y^{\prime}{\frac{h}{2}})
	\\
	&&&=f(x_{j}+\frac{h}{2} , y(x_{j}+\frac{h}{2})+ \bigcirc(h^{2}))
	\\
	&&&=y^{\prime}(x_{j}+\frac{h}{2})+ \bigcirc(h^{2})
	\\
	\\
	&It \hspace{1mm}follows\hspace{1mm} that 
	&y_{j+1} 
	&= y_{j} + f(x_{j}+\frac{h}{2} , y^{*}){h} ,
	\\
	&&&=y_{j} + [y^{\prime}(x_{j}+\frac{h}{2})+ \bigcirc(h^{2})]h
	\\
	&&&=y_{j} + y^{\prime}(x_{j}+\frac{h}{2})h+ \bigcirc(h^{3})
	\end{aligned}
	$
	\\
	Therefore, RK2 is of error $\bigcirc(h^{3})$ at each step. \\
	Hence RK2 is order 2.
	
	\section{Initial Value Problems}
	\subsection{$y^{\prime}=xy$, $y(0)=1$ }
	\subsubsection{Analytic Solution}
	$
	\begin{aligned}
	y^{\prime}
	&=\frac{dy}{dx}=xy
	\\	
	\frac{dy}{y}
	&=xdx
	\\
	\int\frac{dy}{y}
	&=\int xdx
	\\
	\ln(y)
	&=\frac{1}{2}x^{2}+C
	\\
	y
	&=e^{\frac{1}{2}x^{2}+C}=e^{\frac{1}{2}x^{2}}e^{+C}
	\\
	y(0)
	&=1
	\\
	1
	&=e^{\frac{1}{2}(0^{2})}e^{C}=e^{C}
	\\
	C
	&=0
	\\
	y
	&=e^{\frac{1}{2}x^{2}}
	\end{aligned}
	$
	
	\subsubsection{Approximation Error Plots}
	
	The following are log-log plots of the error of numerical approximations. 
	
	\includegraphics[width=120mm]{3b-1-Eu}
	\\
	Here we see Euler's method converging to a slope of 1, thus the error is of order 1.
	\\
	\includegraphics[width=120mm]{3b-1-Quad}
	\\
	Here we see the quadratic method converging to a slope of 2, thus the error is of order 2.
	\\
	\includegraphics[width=120mm]{3b-1-RK2}
	\\
	Here we see the RK2 method converging to a slope of 2, thus the error is of order 2.
	
	\clearpage
	
	\subsubsection{Alternative to RK2}
	
	A modified version of RK2, \\
	$y_{j}=y_{j-1}+\frac{h}{2}f(x_{j-1},y_{j-1})+\frac{h}{2}f(x_{j-1}+h,y_{j-1}+h[f(x_{j-1},y_{j-1})])$
	\\Produces different approximate values.
	
	\begin{center}
		\begin{tabular}{ |c||c|c|c|c| } 
			\hline
			\multicolumn{5}{|c|}{\textbf{Numerical Approximations}} \\
			\hline
			\hline
			Steps & Alternate & RK2 & Alt. Error & RK2 Error \\
			\hline
			1 & 1.5 & 1.5 & 0.14872 & 0.14871 \\ 
			\hline
			2 & 1.61719 & 1.59961 &  0.03154 & 0.04911  \\ 
			\hline
			4 & 1.64229  & 1.63422 & 0.00643  & 0.01450  \\ 
			\hline
			8 & 1.64735 & 1.64477 & 0.00137 & 0.00103  \\ 
			\hline
			16 & 1.64841 & 1.64769 & 0.00031 & 0.00395  \\ 
			\hline
			32 & 1.64865 & 1.64846 & 0.00007 & 0.00026  \\ 
			\hline
			\hline
			$e^{\frac{1}{2}}$ & 1.64872 & 1.64872 & 0 & 0 \\ 
			\hline
		\end{tabular}
	\end{center}
	
	This method converges faster than RK2 for the given initial value problem.
	
	\subsubsection{Differences in Approximate Solutions}
	
	The following are difference plots between the step sizes in numerical approximations. 
	
	\includegraphics[width=150mm]{3d-1-Eu}
	\\
	Here we see the differences in solutions for Euler's method tending to zero as a factor of $x$.
	\\
	\includegraphics[width=150mm]{3d-1-Quad}
	\\
	Here we see the differences in solutions for the quadratic method tending to zero as a factor of $x^{2}$.
	\\
	\includegraphics[width=150mm]{3d-1-RK2}
	\\
	Here we see the differences in solutions for RK2 tending to zero as a factor of $x^{2}$.
	
	\subsection{$y^{\prime}=\dfrac{1}{2}y+9\cos(3x)-\frac{3}{2}\sin(3x)$, $y(0)=1$ }
	\subsubsection{Analytic Solution}
	$
	\begin{aligned}
	y^{\prime}
	&=\frac{1}{2}y+9\cos(3x)-\frac{3}{2}\sin(3x)
	\\
	y^{\prime}-\frac{1}{2}y
	&=9\cos(3x)-\frac{3}{2}\sin(3x)\hspace{3mm},let \hspace{3mm} u(x)=e^{\frac{-1}{2}x}
	\\
	y^{\prime}e^{\frac{-1}{2}x}-\frac{1}{2}ye^{\frac{-1}{2}x}
	&=[(9\cos(3x)-\frac{3}{2}\sin(3x)]e^{\frac{-1}{2}x}
	\\
	y^{\prime}u-yu^{\prime}
	&=[(9\cos(3x)-\frac{3}{2}\sin(3x)]e^{\frac{-1}{2}x}
	\\
	\frac{d}{dx} uy
	&=[(9\cos(3x)-\frac{3}{2}\sin(3x)]e^{\frac{-1}{2}x}
	\\
	uy
	&=\int[(9\cos(3x)-\frac{3}{2}\sin(3x)]e^{\frac{-1}{2}x}dx
	\\
	e^{\frac{-1}{2}x}y
	&=3\sin(3x)e^{\frac{-1}{2}x} + C
	\\
	y
	&=3\sin(3x) + Ce^{\frac{1}{2}x} \hspace{3mm}, \hspace{3mm} y(0)=1
	\\
	1
	&=3\sin(3(0)) + Ce^{\frac{1}{2}(0)}=C
	\\
	y
	&=3\sin(3x) + e^{\frac{1}{2}x}
	\end{aligned}
	$
	
	\subsubsection{Approximation Error Plots}
	
	The following are log-log plots of the error of numerical approximations. 
	
	\includegraphics[width=120mm]{3b-2-Eu}
	\\
	Here we see Euler's method converging to a slope of 1, thus the error is of order 1.
	\\
	\includegraphics[width=120mm]{3b-2-Quad}
	\\
	Here we see the quadratic method converging to a slope of 2, thus the error is of order 2.
	\\
	\includegraphics[width=120mm]{3b-2-RK2}
	\\
	Here we see the RK2 method converging to a slope of 2, thus the error is of order 2.
	
	\subsubsection{Alternative to RK2}
	
	A modified version of RK2, \\
	$y_{j}=y_{j-1}+\frac{h}{2}f(x_{j-1},y_{j-1})+\frac{h}{2}f(x_{j-1}+h,y_{j-1}+h[f(x_{j-1},y_{j-1})])$
	\\Produces different approximate values.
	
	\begin{center}
		\begin{tabular}{ |c||c|c|c|c| } 
			\hline
			\multicolumn{5}{|c|}{\textbf{Numerical Approximations}} \\
			\hline
			\hline
			Steps & Alternate & RK2 & Alt. Error & RK2 Error \\
			\hline
			1 & 24.14747 & 22.58240 & 18.42943 & 16.86435 \\ 
			\hline
			2 & 20.28444 & 4.42807 &  14.56640 & 1.28998  \\ 
			\hline
			4 & 7.12623  & 7.12280 & 1.40819  & 1.40476  \\ 
			\hline
			8 & 6.05043 & 6.18877 & 0.33239 & 0.47073 \\ 
			\hline
			16 & 5.80493 & 5.84905 & 0.08689 & 0.13100  \\ 
			\hline
			32 & 5.74057 & 5.75235 & 0.02252 &  0.03430 \\ 
			\hline
			\hline
			Analytic Solution & 5.71804 & 5.71804 & 0 & 0 \\ 
			\hline
		\end{tabular}
	\end{center}

	
	This method starts worse, but still converges faster than RK2 for the given initial value problem.
	
	\subsubsection{Differences in Approximate Solutions}
	
	The following are difference plots between the step sizes in numerical approximations. 
	
	\includegraphics[width=150mm]{3d-2-Eu}
	\\
	Here we see the differences in solutions for Euler's method tending to zero as a factor of $x$.
	\\
	\includegraphics[width=150mm]{3d-2-Quad}
	\\
	Here we see the differences in solutions for the quadratic method tending to zero as a factor of $x^{2}$.
	\\
	\includegraphics[width=150mm]{3d-2-RK2}
	\\
	Here we see the differences in solutions for RK2 tending to zero as a factor of $x^{2}$.
	
	\section{Appendix}
	
	\begin{lstlisting}
		
	#Python Code, Questions 1,3i)
	
	#Given ODE
	def f(x,y):
		return x*y
	
	#Implicit derivative of the ODE, with respect to x
	def Df(x,y):
		return y+(x*x*y)
		
	
	# The following are all numerical approximations, utilizing loops
	# s is the number of steps
	
	def Alt(s):
		y=1
		x=0
		h=(1/s)
		n=0
		while n<s:
			y=y+(h/2)*(f(x,y)+f(x+h,y+h*f(x,y)))
			x=x+h
			n=n+1
		return y
	
	def Euler(s):
		y=1
		x=0
		h=(1/s)
		n=0
		while n<s:
			y=y+(h*f(x,y))
			x=x+h
			n=n+1
		return y    
	
	def Quad(s):
		y=1
		x=0
		h=(1/s)
		n=0
		while n<s:
			y=y+(h*f(x,y))+((1/2)*(h*h)*Df(x,y))
			x=x+h
			n=n+1
		return y    
	
	def RK2(s):
		y=1
		x=0
		h=(1/s)
		n=0
		while n<s:
			y=y+(h*f(x+(h/2),y+(h/2)*f(x,y)))
			x=x+h
			n=n+1
		return y    
		
	#Python Code, Question 3ii)
	
	import math
	
	#Given ODE
	def f(x,y):
		return ((1/2)*y)+(9*math.cos(3*x))-((3/2)*math.sin(3*x))
	
	#Implicit derivative of the ODE, with respect to x
	def Df(x,y):
		return (1/2)*f(x,y)-(27*math.sin(3*x))-((9/2)*math.cos(3*x))
	
	# The following are all numerical approximations, utilizing loops
	# s is the number of steps
	
	def Alt(s):
		y=1
		x=0
		h=(3/s)
		n=0
		while n<s:
			y=y+(h/2)*(f(x,y)+f(x+h,y+h*f(x,y)))
			x=x+h
			n=n+1
		return y
	
	def Euler(s):
		y=1
		x=0
		h=(3/s)
		n=0
		while n<s:
			y=y+(h*f(x,y))
			x=x+h
			n=n+1
		return y    
	
	def Quad(s):
		y=1
		x=0
		h=(3/s)
		n=0
		while n<s:
			y=y+(h*f(x,y))+((1/2)*(h*h)*Df(x,y))
			x=x+h
			n=n+1
		return y    
	
	def RK2(s):
		y=1
		x=0
		h=(3/s)
		n=0
		while n<s:
			y=y+(h*f(x+(h/2),y+(h/2)*f(x,y)))
			x=x+h
			n=n+1
		return y    
	
	\end{lstlisting}
	
	\end{document}